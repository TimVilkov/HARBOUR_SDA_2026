{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22a599a9",
   "metadata": {},
   "source": [
    "# HW ‚Äî Hypothesis Testing with ARPU / Revenue per User\n",
    "\n",
    "## Context\n",
    "You are a data analyst on a mobile game team. The team launched a change in onboarding / paywall / checkout and asks you to evaluate impact using **ARPU (Average Revenue Per User)**.\n",
    "\n",
    "For this homework, ARPU is computed at the **user level over the whole period**:\n",
    "\n",
    "1) First aggregate revenue per user over the period:\n",
    "$Revenue_u = \\sum_{d \\in period} revenue_{u,d}$\n",
    "\n",
    "2) Then compute ARPU as the mean across users:\n",
    "$ARPU = \\dfrac{1}{N}\\sum_{u=1}^{N} Revenue_u$\n",
    "\n",
    "Why ARPU is commonly used:\n",
    "- In A/B tests with equal-sized groups, $\\Delta ARPU$ is directly proportional to the difference in **total revenue** between groups:\n",
    "  $TotalRevenue = N \\cdot ARPU$\n",
    "  so comparing ARPU is equivalent to comparing total revenue (up to a constant factor).\n",
    "\n",
    "Revenue data is usually tricky:\n",
    "- many users have **zero revenue**\n",
    "- heavy tails (rare users with very large payments)\n",
    "\n",
    "Because of that, we want to be careful with ‚Äústandard‚Äù asymptotic tests.\n",
    "\n",
    "You have two files:\n",
    "- `history_activity.csv` ‚Äî pre-period (1 month)\n",
    "- `current_activity.csv` ‚Äî current period (1 month) + `bucket` (0/1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8427edb4",
   "metadata": {},
   "source": [
    "# Task 1 ‚Äî Pre-period visualization (history_activity.csv)\n",
    "\n",
    "Work only with `history_activity.csv`.\n",
    "\n",
    "Build daily time series:\n",
    "\n",
    "1) **DAU**: number of unique users with `revenue > 0` on that day  \n",
    "2) **Daily ARPU**: mean revenue per user-day:\n",
    "   $ARPU(d) = mean_u(revenue_{u,d})$\n",
    "3) **Share of payers** per day:\n",
    "   $\\pi(d) = \\dfrac{\\#\\{u: revenue_{u,d} > 0\\}}{\\#\\{u\\}}$\n",
    "\n",
    "Make 3 plots (one per metric).\n",
    "\n",
    "Write 3‚Äì5 sentences:\n",
    "- is there seasonality / trend?\n",
    "- is the payer share stable?\n",
    "- do you see signs of heavy tails (spikes)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1144db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f712d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f38c8",
   "metadata": {},
   "source": [
    "# Task 2 ‚Äî Is the asymptotic z/t-test calibrated for ARPU?\n",
    "\n",
    "We want to check if the standard asymptotic test for the difference in means behaves correctly under **AA** (no real effect).\n",
    "\n",
    "## Setup\n",
    "1) Aggregate the pre-period into **one row per user**:\n",
    "   $revenue_u = \\sum_d revenue_{u,d}$\n",
    "\n",
    "2) Repeat many times:\n",
    "- randomly split users into two equal groups A and B\n",
    "- run an asymptotic test for difference in mean revenue (asymptotic z-test)\n",
    "- store the p-value\n",
    "\n",
    "## What to check\n",
    "- **Alpha control**: $P(p < 0.05)$ should be close to 0.05\n",
    "- **Uniformity**: p-values should look approximately Uniform(0,1)\n",
    "  (histogram + QQ plot)\n",
    "\n",
    "If calibration is poor, it means naive asymptotic inference may be misleading for heavy-tailed revenue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c9fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe3874",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ba316",
   "metadata": {},
   "source": [
    "If you did everything correctly, you should see that under AA:\n",
    "- the rejection rate at $\\alpha=0.05$ is close to 0.05\n",
    "- p-values look approximately Uniform(0,1)\n",
    "\n",
    "This means the asymptotic test for the difference in mean ARPA is reasonably well-calibrated for our data.\n",
    "\n",
    "Now we can move on to the practical question: **what experiment design can we afford and what is optimal for us?**\n",
    "Next, we will think about sample size, duration, and variance reduction options (e.g., stratification / CUPED), and choose a design that achieves the required power with minimal cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243605fc",
   "metadata": {},
   "source": [
    "# Task 3 ‚Äî Experiment design: how long do we need to run?\n",
    "\n",
    "We are ready to run an A/B test, but first we must answer a basic design question:\n",
    "\n",
    "**Given our traffic and the variability of ARPU, how long should the experiment run to detect meaningful effects?**\n",
    "\n",
    "To answer this, we will compute the **minimum detectable effect (MDE)** for different experiment durations and test settings.\n",
    "\n",
    "## Step 1 ‚Äî Estimate weekly traffic\n",
    "Using `history_activity.csv`:\n",
    "- compute the average number of weekly unique users\n",
    "\n",
    "Call this value $T$ = **unique users per week**.\n",
    "\n",
    "## Step 2 ‚Äî Convert weeks to total sample size\n",
    "For a duration of $w$ weeks:\n",
    "$N(w) = T \\cdot w$\n",
    "\n",
    "We will consider:\n",
    "$w \\in \\{1,2,3,4,5,6,7,8\\}$  \n",
    "(so $N(w)$ is up to ~800k)\n",
    "\n",
    "## Step 3 ‚Äî Compute relative MDE for ARPU\n",
    "Using `history_daily.csv`, estimate baseline ARPU variability on the same window length:\n",
    "- $Revenue_u = \\sum_{d \\in window} revenue_{u,d}$\n",
    "- $ARPU = mean_u(Revenue_u)$\n",
    "\n",
    "Then compute **relative MDE (%)** for:\n",
    "- $\\alpha \\in \\{0.01, 0.05, 0.10\\}$ (two-sided)\n",
    "- power $\\in \\{0.75, 0.80\\}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f61062",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48910fac",
   "metadata": {},
   "source": [
    "### Why with n grows MDE decreases slower? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86cb812",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cdc83d",
   "metadata": {},
   "source": [
    "It looks like with a standard choice of $\\alpha = 0.05$ and power $= 0.80$ we would need to run the experiment for about **4 weeks**, and even then the **relative MDE for ARPU is quite high**.\n",
    "\n",
    "We discussed this with the product manager. They say we **cannot wait longer than 4 weeks**, so we commit to:\n",
    "- **two-sided $\\alpha = 0.05$**\n",
    "- **power $= 0.80$ (i.e., $\\beta = 0.20$)**\n",
    "- **duration = 4 weeks**\n",
    "\n",
    "The product manager has high confidence in the change and believes the expected effect is large, so this MDE is acceptable for a go/no-go decision.\n",
    "\n",
    "At the same time, we still want to understand *what drives the revenue change*.  \n",
    "ARPU can increase because:\n",
    "- more users convert to payment (**payer rate** goes up), and/or\n",
    "- paying users spend more (**ARPPU** goes up)\n",
    "\n",
    "So we will **decompose ARPU** and compute MDE not only for ARPU, but also for:\n",
    "1) **Payer Rate**: $P(Revenue_u > 0)$ over the experiment window  \n",
    "2) **ARPPU**: $E[Revenue_u \\mid Revenue_u > 0]$ over the experiment window\n",
    "\n",
    "These are not decision metrics, but they help interpret the mechanism behind any ARPU movement.\n",
    "\n",
    "## Questions\n",
    "1) What are the MDE values for these three metrics?\n",
    "2) How do you interpret them?  \n",
    "   Which component (conversion vs spend among payers) is easier to detect and why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe6ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97760c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5421c91",
   "metadata": {},
   "source": [
    "Typically, the MDE for **payer rate** and **ARPPU** is lower than for ARPU.  \n",
    "That means these metrics are often more sensitive and can help us understand *what exactly changed*:\n",
    "- did we improve **conversion to payment**?\n",
    "- or did we increase **revenue per payer** (order size)?\n",
    "\n",
    "However, our original business goal is **ARPU**.  \n",
    "So we will treat payer rate and ARPPU as **proxy / diagnostic metrics**: they help interpret the outcome, but they do not replace the primary objective.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01802b4e",
   "metadata": {},
   "source": [
    "# Task 4 ‚Äî Define the OEC (template)\n",
    "\n",
    "Read about OEC here:\n",
    "https://www.analytics-toolkit.com/glossary/overall-evaluation-criterion/\n",
    "\n",
    "Fill in the fields below.\n",
    "\n",
    "## 1) Product hypothesis\n",
    "Write one clear hypothesis (generate any idea which potentially can increase ARPU in our mobile game):\n",
    "\n",
    "> ‚ÄúIf we ______, then ______ will change because ______.‚Äù\n",
    "\n",
    "(1‚Äì2 sentences total.)\n",
    "\n",
    "---\n",
    "\n",
    "## 2) OEC (Overall Evaluation Criterion)\n",
    "\n",
    "### Primary metric (ARPU)\n",
    "For each user:\n",
    "$Revenue_u = \\sum_{d \\in experiment} revenue_{u,d}$\n",
    "\n",
    "Then:\n",
    "$ARPU = \\dfrac{1}{N}\\sum_u Revenue_u$\n",
    "\n",
    "### Success criterion (fixed for this homework)\n",
    "We declare success if:\n",
    "- **ARPU uplift ‚â• {insert your relative MDE}**:\n",
    "  $\\dfrac{ARPU_B - ARPU_A}{ARPU_A} \\ge  MDE$\n",
    "- and the result is statistically significant with **two-sided $\\alpha = 0.05$**\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Proxy / diagnostic metrics (interpretation only)\n",
    "\n",
    "**Payer rate**:\n",
    "$payer_u = 1[Revenue_u > 0]$  \n",
    "$PayerRate = mean_u(payer_u)$\n",
    "\n",
    "**ARPPU**:\n",
    "$ARPPU = E[Revenue_u \\mid Revenue_u > 0]$\n",
    "\n",
    "Fill in:\n",
    "- If ARPU increases mainly via **payer rate**, it means ____________________________.\n",
    "- If ARPU increases mainly via **ARPPU**, it means ______________________________.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65aa7e4",
   "metadata": {},
   "source": [
    "Great, we are ready to launch!\n",
    "\n",
    "The product manager thanks you for the preparation:\n",
    "- you validated that the chosen statistical test is well-calibrated under AA (alpha is controlled),\n",
    "- the experiment design matches the business goal (primary decision is based on ARPU),\n",
    "- and you defined helpful diagnostic metrics (payer rate and ARPPU) that will let us understand *why* ARPU changes (conversion vs revenue per payer).\n",
    "\n",
    "Now we can run the experiment and analyze the results using the agreed OEC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39164e95",
   "metadata": {},
   "source": [
    "# Experiment analysis ‚Äî Step 1: Sanity check for the splitter (SRM)\n",
    "\n",
    "Before looking at business impact, we should verify that randomization worked correctly.\n",
    "\n",
    "A common issue is **Sample Ratio Mismatch (SRM)**: the observed number of users in A and B differs from the expected split (e.g., 50/50). This can indicate problems in the splitter or data collection.\n",
    "\n",
    "We test SRM using a **chi-square goodness-of-fit** test:\n",
    "- $H_0$: group assignment follows the expected split (50/50)\n",
    "- $H_1$: observed split differs from expected\n",
    "\n",
    "If the p-value is small (e.g., < 0.05), we suspect SRM and should not trust the experiment results until investigated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64896e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562bc758",
   "metadata": {},
   "source": [
    "So far so good, nothing suspicious, let's move forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46031e22",
   "metadata": {},
   "source": [
    "# Task 5 ‚Äî Build an A/B report table (experiment results)\n",
    "\n",
    "The experiment is finished and all data is available.\n",
    "\n",
    "Your goal is to produce a clean A/B report table with the main results for **three metrics**:\n",
    "1) **ARPU** (28-day revenue per user)\n",
    "2) **Payer rate**: $P(Revenue_u > 0)$\n",
    "3) **ARPPU**: $E[Revenue_u \\mid Revenue_u > 0]$\n",
    "\n",
    "## Step 1 ‚Äî Prepare user-level dataset\n",
    "Work with `current_daily.csv`.\n",
    "\n",
    "For the first 28 days of the experiment:\n",
    "- aggregate to **one row per user**:\n",
    "  $Revenue_u = \\sum_d revenue_{u,d}$\n",
    "- keep the user‚Äôs bucket (0/1)\n",
    "\n",
    "## Step 2 ‚Äî Compute per-metric stats\n",
    "For each metric, report:\n",
    "\n",
    "- **Control mean**\n",
    "- **Treatment mean**\n",
    "- **Absolute lift**: $\\Delta = \\bar{X}_B - \\bar{X}_A$\n",
    "- **Relative lift (%)**: $\\Delta / \\bar{X}_A$\n",
    "- **Standard error** of $\\Delta$\n",
    "- **95% CI** for $\\Delta$\n",
    "- **p-value**\n",
    "\n",
    "Use asymptotic tests:\n",
    "- ARPU: Asymptotic z-test on user-level $Revenue_u$\n",
    "- Payer rate: Asymptotic z-test on user-level\n",
    "- ARPPU: Asymptotic z-test on payer-only $Revenue_u$ values\n",
    "\n",
    "## Step 3 ‚Äî Format the report\n",
    "Create a table (DataFrame) with one row per metric and apply styling:\n",
    "- highlight rows with **p-value < 0.05** (e.g., green)\n",
    "- display readable numeric formatting (rounding)\n",
    "\n",
    "The output should look like a standard experiment report table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bef678",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da321e9",
   "metadata": {},
   "source": [
    "## Interpretation questions (write-up)\n",
    "\n",
    "Look at the A/B report table for:\n",
    "- ARPU\n",
    "- payer rate\n",
    "- ARPPU\n",
    "\n",
    "Answer in a few sentences:\n",
    "\n",
    "1) **What happened in the experiment?**  \n",
    "   Describe the direction of changes for all three metrics (up / down / no clear change).\n",
    "\n",
    "2) **What could have happened product-wise?**  \n",
    "   Give 1‚Äì2 plausible product explanations based on the pattern you see.\n",
    "\n",
    "3) **Do we consider the experiment successful? Why?**  \n",
    "   Use the OEC:\n",
    "   Clearly state whether it is a win / loss / inconclusive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f59a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1ef47d",
   "metadata": {},
   "source": [
    "## Note on confidence intervals for relative lift\n",
    "\n",
    "Be careful when reporting confidence intervals for **relative lift**:\n",
    "$L = \\dfrac{\\bar{X}_B - \\bar{X}_A}{\\bar{X}_A}$\n",
    "\n",
    "Even if the underlying metric is a simple mean (like ARPU), **relative lift is a ratio** because the denominator $\\bar{X}_A$ is random.  \n",
    "This can cause subtle issues:\n",
    "- naive transformations of an absolute CI into a relative CI (e.g., ‚Äúdivide CI endpoints by $\\bar{X}_A$‚Äù) may be inaccurate\n",
    "- coverage can be distorted, especially with heavy-tailed data or small samples\n",
    "- for ratio metrics (or near-zero denominators) the problem becomes even more pronounced\n",
    "\n",
    "If you want to go deeper, see:\n",
    "- https://alexdeng.github.io/public/files/kdd2018-dm.pdf\n",
    "- https://www.landonlehman.com/post/confidence-intervals-for-relative-lift/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede1f84",
   "metadata": {},
   "source": [
    "# CUPED (variance reduction): can we decide faster using historical data?\n",
    "\n",
    "If we have a good pre-period signal for the same users, we can often reduce variance and detect effects faster.\n",
    "\n",
    "Before applying CUPED, we need to check a basic feasibility question:\n",
    "\n",
    "## Task 6\n",
    "Using `current_daily.csv` (experiment users) and `history_daily.csv` (pre-period):\n",
    "\n",
    "1) Define the experiment user set:\n",
    "- all unique `user_id` present in the first 28 days of `current_daily.csv`\n",
    "\n",
    "2) For these users, check how many have historical data:\n",
    "- a user ‚Äúhas history‚Äù if they appear at least once in `history_daily.csv`\n",
    "\n",
    "Compute:\n",
    "- share of experiment users with history:\n",
    "  $\\text{coverage} = \\dfrac{|U_{exp} \\cap U_{hist}|}{|U_{exp}|}$\n",
    "\n",
    "Report this share as a percentage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2951bf8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18562d0",
   "metadata": {},
   "source": [
    "## CUPED: how much variance reduction do we get, and how much time can we save?\n",
    "\n",
    "From the lecture, CUPED reduces variance approximately by a factor:\n",
    "$\\mathrm{Var}_{new} \\approx (1-\\rho^2)\\,\\mathrm{Var}_{old}$\n",
    "\n",
    "where $\\rho$ is the correlation between:\n",
    "- the **pre-period** user metric (covariate)\n",
    "- the **experiment-period** user metric (outcome)\n",
    "\n",
    "## Task\n",
    "1) For each user in the experiment, compute:\n",
    "- $X_u$ = pre-period revenue (sum over the pre-period window)\n",
    "- $Y_u$ = experiment-period revenue (sum over the experiment window)\n",
    "\n",
    "2) Compute the correlation $\\rho = corr(X, Y)$ using only users with both $X_u$ and $Y_u$.\n",
    "\n",
    "3) Compute the theoretical variance reduction:\n",
    "- variance multiplier: $(1-\\rho^2)$\n",
    "- variance reduction (%): $100 \\cdot \\rho^2$\n",
    "\n",
    "4) Translate variance reduction into time reduction:\n",
    "For a fixed MDE, required sample size scales linearly with variance, so required duration scales similarly:\n",
    "$\\text{weeks}_{new} \\approx (1-\\rho^2)\\cdot \\text{weeks}_{old}$\n",
    "\n",
    "Assume $\\text{weeks}_{old} = 4$ and estimate $\\text{weeks}_{new}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e09c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c09e035",
   "metadata": {},
   "source": [
    "If you did everything correctly, you should see that **CUPED barely helps in this dataset**.\n",
    "\n",
    "Even though there is a large overlap between experiment users and pre-period users, the correlation $\\rho$ between\n",
    "pre-period revenue $X_u$ and experiment-period revenue $Y_u$ is very small. As a result:\n",
    "- $\\rho^2$ is close to 0\n",
    "- the variance multiplier $(1-\\rho^2)$ is close to 1\n",
    "- the estimated time reduction is almost zero\n",
    "\n",
    "**Explain why this happens in our setting even if overlap is high? (both product-wise and from statistical perspective)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b6099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99df598",
   "metadata": {},
   "source": [
    "# Task 7. What happens if we ‚Äúpeek‚Äù every day?\n",
    "\n",
    "So far we assumed a fixed horizon: we run the experiment for a planned duration and decide once at the end.\n",
    "\n",
    "Now let‚Äôs simulate a very common anti-pattern:\n",
    "> ‚ÄúWe stop the experiment on the first day when p-value < Œ±‚Äù.\n",
    "\n",
    "Even if there is **no real effect** (AA / null), repeated daily looks inflate the false positive rate:\n",
    "- nominal $\\alpha=0.05$ no longer means ‚Äú5% false positives‚Äù\n",
    "- the real probability of a false win becomes much higher\n",
    "\n",
    "## Goal\n",
    "Simulate many AA experiments and estimate the **real FPR**:\n",
    "- **FPR** = share of experiments where p-value becomes < Œ± **at least once** during the timeline\n",
    "\n",
    "Also plot random p-value trajectories and color **red** those that cross the threshold at least once.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eeaf80",
   "metadata": {},
   "source": [
    "## Important: this simulation must be AA (null)\n",
    "\n",
    "To estimate the **false positive rate** of ‚Äústop when p-value < Œ±‚Äù, we must simulate **AA experiments** (no real effect).\n",
    "That means we should use **pre-period data** (`history_activity.csv`) and randomly split users into A/B.\n",
    "\n",
    "We should NOT use the finished experiment data (`current_activity.csv`) for this step, because it may contain a real treatment effect (or other changes), and then the result would no longer measure FPR under the null.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2797ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde39ba2",
   "metadata": {},
   "source": [
    "As you can see, making a decision by ‚Äúpeeking‚Äù every day and stopping at the first time $p < \\alpha$ is very dangerous.\n",
    "\n",
    "Even under AA (no true effect), repeated looks greatly increase the chance of crossing the threshold at least once.  \n",
    "So the nominal $\\alpha = 0.05$ no longer means ‚Äú5% false positives‚Äù ‚Äî the real false positive rate becomes much higher.\n",
    "\n",
    "Conclusion: **without special corrections, you must not make decisions this way**.  \n",
    "If early stopping is required, you need a sequential design (e.g., alpha-spending / group sequential boundaries) that preserves the overall type I er\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7071f0",
   "metadata": {},
   "source": [
    "# Task 8 ‚Äî Multiple metrics: ‚Äúwin if at least one is significant‚Äù\n",
    "\n",
    "So far our decision rule used a single primary metric (ARPU).  \n",
    "Now consider a risky alternative rule:\n",
    "\n",
    "> ‚ÄúWe declare a win if **at least one** of the three metrics is statistically significant at $\\alpha=0.05$.‚Äù\n",
    "\n",
    "Metrics:\n",
    "1) ARPU  \n",
    "2) payer rate  \n",
    "3) ARPPU  \n",
    "\n",
    "Even under AA (no real effect), this rule inflates the false positive rate because we run multiple tests.\n",
    "\n",
    "## Goal\n",
    "Using AA simulations on `history_daily.csv`:\n",
    "- repeatedly split users into two equal groups A/B\n",
    "- compute p-values for the 3 metrics\n",
    "- declare a ‚Äúwin‚Äù if $\\min(p_1,p_2,p_3) < 0.05$\n",
    "\n",
    "Estimate the **real alpha**:\n",
    "$\\alpha_{real} = P(\\text{at least one significant})$\n",
    "and compare it to 0.05.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af44e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7861a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86bade7",
   "metadata": {},
   "source": [
    "## As you can see, even though these three metrics are strongly dependent (they all reflect the same payment behavior), using the rule\n",
    "\n",
    "> ‚Äúdeclare a win if at least one metric is significant‚Äù\n",
    "\n",
    "still inflates the false positive rate.  \n",
    "This is dangerous: you will report ‚Äúwins‚Äù under AA more often than the nominal $\\alpha=0.05$, even without any true effect.\n",
    "\n",
    "---\n",
    "\n",
    "## Congrats üéâ\n",
    "\n",
    "You have finished this homework.\n",
    "\n",
    "I hope it was interesting and useful. Please leave any feedback below (anything is welcome: clarity, difficulty, what to add/remove).\n",
    "\n",
    "Thank you!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
