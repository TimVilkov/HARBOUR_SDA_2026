{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d7a35d",
   "metadata": {},
   "source": [
    "# Task 1. Latency Police (20 points)\n",
    "\n",
    "Story. A company (QuickAPI) advertises:\n",
    "\n",
    "“During peak hours, the average API latency does not exceed 200 ms.”\n",
    "\n",
    "You collected n = 25 peak-hour latencies (ms). Assume i.i.d. Exponential waiting times with mean $\\mu$\n",
    "\n",
    "\n",
    "Your job: decide whether the ad claim looks consistent with the data or it's just a clickbait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "226f1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_obs = np.array([\n",
    "    93.85, 260.75, 172.69, 137.36, 33.92,\n",
    "    33.92, 11.97, 201.12, 137.44, 163.07,\n",
    "     4.15, 350.36, 228.45, 47.78, 40.13,\n",
    "    40.62, 72.53, 117.11, 109.62, 74.02,\n",
    "    61.28, 134.49, 96.49, 89.88, 108.20\n",
    "])\n",
    "n = len(x_obs)\n",
    "mu0 = 200.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceb83ea",
   "metadata": {},
   "source": [
    "## Translate the ad claim into hypotheses (2 points)\n",
    "\n",
    "\n",
    "QuickAPI claims: “During peak hours, the average API latency does not exceed 200 ms.”\n",
    "\n",
    "Write statistical hypotheses. Decide one-sided vs two-sided. Argue your answer.\n",
    "\n",
    "What alpha level you will use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b668377",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b54117d",
   "metadata": {},
   "source": [
    "## Statistic (1 point)\n",
    "\n",
    "We will use one statistic for the whole task:\n",
    "\n",
    "$S=\\sum_{i=1}^{n} X_i$\n",
    "\n",
    "Compute $S_{obs}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d939deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_obs = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297ecff0",
   "metadata": {},
   "source": [
    "## Statistic distribution (2 points)\n",
    "\n",
    "Under the boundary of the null ($\\mu=\\mu_0$), find the exact distribution of $S$ and its parameters.\n",
    "\n",
    "Write 2–5 lines explaining where it comes from and include a non-AI citation (textbook / lecture notes).\n",
    "\n",
    "Then define the parameters in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35c7c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedbf806",
   "metadata": {},
   "source": [
    "## Plot distribution of your statistic under null hypothesis. (2 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b65f7f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645ab7ed",
   "metadata": {},
   "source": [
    "## Add rejection region and observed value (3 points)\n",
    "\n",
    "\n",
    "mark $S_{obs}$ as a vertical line\n",
    "\n",
    "mark $c$ as a vertical line\n",
    "\n",
    "shade the rejection region ($S \\ge c$)\n",
    "\n",
    "Do your reject $H_0$ or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "818562b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c90486",
   "metadata": {},
   "source": [
    "## Simulation check: does the exact test control $\\alpha$? (4 points)\n",
    "\n",
    "We now verify the test by simulation under the boundary $\\mu=\\mu_0$.\n",
    "\n",
    "Simulate many datasets from Exp(mean=$\\mu_0$), each of size $n$:\n",
    "\n",
    "1. compute $S$\n",
    "\n",
    "2. compute the exact p-value for each run\n",
    "\n",
    "3. estimate the rejection rate at your chosen $\\alpha$\n",
    "\n",
    "Report the simulated rejection rate and compare it to $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bb0b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f316e",
   "metadata": {},
   "source": [
    "## Apply asymptotic Z-test to the same problem: is False Positive Rate as expected? (4 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df1c0700",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794c1d66",
   "metadata": {},
   "source": [
    "## Plot p-value distribution for the exact test and for the asymptotic one. (2 points)\n",
    "\n",
    "What do you see? Are both tests correct? Explain why we see such results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f83b433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ade39",
   "metadata": {},
   "source": [
    "# Task 2. The T-test myth (20 points)\n",
    "\n",
    "Story. Your teammate says:\n",
    "\n",
    "> “In industry everyone uses the classic two-sample $t$-test or Welch's $t$-test. It’s robust and basically assumption-free: you only need i.i.d. samples. Normality is not a real requirement.”\n",
    "\n",
    "You will stress-test this claim on a **small sample** from a **clearly non-normal** distribution.\n",
    "\n",
    "**Fixed setup (do not change):**\n",
    "We run an A/A test: both groups are sampled from the same skewed distribution, so there is **no real effect**.\n",
    "\n",
    "$X_1,\\dots,X_{n_1} \\overset{iid}{\\sim} \\mathrm{LogNormal}(0,1^2), \\qquad\n",
    "Y_1,\\dots,Y_{n_2} \\overset{iid}{\\sim} \\mathrm{LogNormal}(0,1^2), \\qquad\n",
    "X \\perp Y.$\n",
    "\n",
    "For simplicity we use the **pooled two-sample $t$-test** because in this simulation the true variances are equal; this avoids varying degrees of freedom.\n",
    "\n",
    "Fixed parameters:\n",
    "- $n_1=n_2=20$\n",
    "- seed = `7`\n",
    "- simulations $R=50{,}000$\n",
    "- $\\alpha=0.05$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9db1d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "n1 = 20\n",
    "n2 = 20\n",
    "R = 50_000\n",
    "\n",
    "# A/A simulations: shape (R, n)\n",
    "x = rng.lognormal(mean=0.0, sigma=1.0, size=(R, n1))\n",
    "y = rng.lognormal(mean=0.0, sigma=1.0, size=(R, n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "897dfd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 20)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd9e6a",
   "metadata": {},
   "source": [
    "## 1) Do pooled t-statistics actually look like Student-$t$ here? (4 points)\n",
    "\n",
    "- Simulate $R$ experiments under $H_0$ and compute the pooled two-sample $t$ statistic each time.\n",
    "- Plot the histogram (density) of simulated $t$.\n",
    "- Overlay a Student-$t$ density with $\\nu=n_1+n_2-2$.\n",
    "- Do the shapes match? If not, describe the mismatch (center vs tails vs asymmetry).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1bd112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac20e9",
   "metadata": {},
   "source": [
    "## 2) Does the pooled t-test control $\\alpha=0.05$ in this setting? (4 points)\n",
    "\n",
    "- Under the same $H_0$, compute pooled **two-sided** $t$-test p-values for all $R$ experiments.\n",
    "- Estimate empirical false positive rate:\n",
    "  $\\widehat{\\mathrm{FPR}}=\\Pr(p \\le 0.05).$\n",
    "- Plot the p-value histogram.\n",
    "- Is it close to  $U(0,1)$? If not, in what direction is it distorted?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0bc51439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac8852",
   "metadata": {},
   "source": [
    "## 3) PIT check: is the Student-$t$ CDF the right CDF for these pooled $t$’s? (4 points)\n",
    "\n",
    "Probability integral transform (PIT) fact:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Probability_integral_transform\n",
    "\n",
    "If a random variable $T$ truly has CDF $F$, then\n",
    "$U = F(T)$\n",
    "must be $U(0,1)$.\n",
    "\n",
    "- For each run compute\n",
    "  $U = F_{t,\\nu}(t),$\n",
    "  where $F_{t,\\nu}$ is the Student-$t$ CDF and $\\nu = n_1+n_2-2$.\n",
    "- Plot the histogram of $U$.\n",
    "- Is it flat? If not, interpret the shape (what kind of mismatch does it suggest?).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38758abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39bed36",
   "metadata": {},
   "source": [
    "## 4) Check the chi-square piece (4 points)\n",
    "\n",
    "Textbook (normal-theory) identity for the **pooled two-sample $t$-test**:\n",
    "\n",
    "$\n",
    "t = \\frac{Z}{\\sqrt{\\chi^2_\\nu/\\nu}},\n",
    "\\qquad\n",
    "Z\\sim \\mathcal N(0,1),\\;\\; \\chi^2_\\nu \\text{ independent},\\;\\;\n",
    "\\nu = n_1+n_2-2.\n",
    "$\n",
    "\n",
    "In our A/A simulation the data are **not normal**, so this identity is not guaranteed.\n",
    "We will **test whether the chi-square part still looks right**.\n",
    "\n",
    "For each simulated run compute the pooled variance $s_p^2$ and build:\n",
    "\n",
    "$\n",
    "Q = \\frac{\\nu\\, s_p^2}{\\sigma^2_{\\text{true}}}.\n",
    "$\n",
    "\n",
    "If the textbook story held, then we would expect:\n",
    "\n",
    "$\n",
    "Q \\sim \\chi^2_\\nu.\n",
    "$\n",
    "\n",
    "Make:\n",
    "- a QQ plot of empirical $Q$ vs $\\chi^2_\\nu$ quantiles\n",
    "- a PIT check: $V = F_{\\chi^2_\\nu}(Q)$ should be close to $U(0,1)$ if $Q$ is really chi-square\n",
    "\n",
    "Describe what breaks and why non-normality can cause it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1524b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d9a5a2",
   "metadata": {},
   "source": [
    "## 5) One-paragraph conclusion (4 points)\n",
    "\n",
    "In 5–8 lines, answer:\n",
    "\n",
    "- In this fixed setup, is the “t-test is assumption-free” claim supported or not?\n",
    "- If it fails, describe *how* it fails\n",
    "- What practical rule of thumb would you tell a teammate about using the pooled t-test?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dab884",
   "metadata": {},
   "source": [
    "\\# your conclusion here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c26d8b3",
   "metadata": {},
   "source": [
    "# Task 3. The MW test myth (20 points)\n",
    "\n",
    "Mann–Whitney U (MWU) sometimes is used in A/B testing as a “robust non-parametric alternative” to the $t$-test when data are non-normal or heavy-tailed.\n",
    "Your goal is to verify this belief and deliver a verdict:\n",
    "\n",
    "Can MWU replace a mean test (e.g., $t$-test / asymptotic $z$-test for $\\mu_B-\\mu_A$) without changing the hypothesis?\n",
    "\n",
    "Does it produce “more robust” decisions for mean-based business metrics (e.g., ARPU)?\n",
    "\n",
    "https://stripe.com/en-es/resources/more/what-is-average-revenue-per-user-why-it-matters-and-how-to-calculate-it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0a09a7",
   "metadata": {},
   "source": [
    "## 1) Simulate many datasets under $H_0$ with $n=2000$ per group. (7 points)\n",
    "\n",
    "For each simulation compute the asymptotic Z statistic\n",
    "\n",
    "$z = \\dfrac{\\bar{Y}-\\bar{X}}{\\sqrt{s_X^2/n + s_Y^2/n}}$\n",
    "\n",
    "two-sided p-value from $z$\n",
    "\n",
    "Plot:\n",
    "\n",
    "- histogram of $z$\n",
    "\n",
    "- histogram of p-values\n",
    "\n",
    "Check:\n",
    "\n",
    "- empirical FPR at $\\alpha=0.05$ is close to $0.05$\n",
    "\n",
    "- $z$ looks close to $\\mathcal{N}(0,1)$\n",
    "\n",
    "- p-values look close to $\\text{Uniform}(0,1)$\n",
    "\n",
    "Question: are the means equal by construction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad675898",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000\n",
    "rng = np.random.default_rng(2025)\n",
    "\n",
    "# N(0,1)\n",
    "A = rng.normal(0.0, 1.0, n)\n",
    "\n",
    "# mixture with rare outliers\n",
    "p, mu1 = 0.98, 8.0\n",
    "mu0 = -((1 - p) / p) * mu1\n",
    "B = np.where(rng.random(n) < p,\n",
    "             rng.normal(mu0, 1.0, n),\n",
    "             rng.normal(mu1, 1.0, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f9024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a85e43",
   "metadata": {},
   "source": [
    "## 2) Mann–Whitney U on the same data (7 points)\n",
    "\n",
    "What to do\n",
    "\n",
    "1. Using the same $X$ and $Y$ as in Task 1 (means equal), simulate 2000 samples.\n",
    "\n",
    "2. Run Mann–Whitney U (two-sided, asymptotic) at $\\alpha=0.05$.\n",
    "\n",
    "3. Report the empirical rejection rate.\n",
    "\n",
    "Questions:\n",
    "\n",
    "1. If MWU is used to test equality of means, what is the conceptual mistake?\n",
    "\n",
    "2. What risks does this create in A/B decisions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "545b50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yur code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e9057",
   "metadata": {},
   "source": [
    "## 3) ARPU: construct a bad example (6 points)\n",
    "\n",
    "Build a concrete ARPU setup where the distribution changes is in opposite with MWU test result.\n",
    "\n",
    "Simulate many experiments with $n=2000$ per group.\n",
    "\n",
    "Run right-sided MWU for “B greater than A”.\n",
    "\n",
    "Questions:\n",
    "\n",
    "1. Can MWU reject $H_0$ in favor of “B is better” while the ARPU mean in B is lower?\n",
    "\n",
    "2. If yes, explain why this can happen for ARPU-like metrics.\n",
    "\n",
    "Reference (for inspiration): https://blog.analytics-toolkit.com/2024/stop-abusing-the-mann-whitney-u-test-mwu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6c3cd87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yur code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a331082",
   "metadata": {},
   "source": [
    "# Task 4. Confidence Intervals comparison (20 points)\n",
    "\n",
    "You are estimating a Bernoulli probability p with small samples. Different confidence intervals behave very differently, especially near p≈0 or p≈1. Your job is to build and compare them via simulation.\n",
    "\n",
    "We will use:\n",
    "\n",
    "- n = 10 and n = 30 (and later vary n)\n",
    "\n",
    "- confidence level 1 - α = 0.95\n",
    "\n",
    "Intervals to implement by hand:\n",
    "\n",
    "1. Wald\n",
    "\n",
    "2. Wilson\n",
    "\n",
    "3. Agresti–Coull\n",
    "\n",
    "4. Clopper–Pearson (exact)\n",
    "\n",
    "https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d2d9fe",
   "metadata": {},
   "source": [
    "## Implement Wald CI (3 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "423edf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65775eab",
   "metadata": {},
   "source": [
    "## Implement Wilson + Agresti–Coull (3 points)\n",
    "\n",
    "Write two functions: ci_wilson, ci_agresti_coull.\n",
    "\n",
    "No helper packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08e947fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca5f583",
   "metadata": {},
   "source": [
    "## Implement Clopper–Pearson (exact) (3 points)\n",
    "\n",
    "Use Beta distribution quantiles (you may use scipy.stats.beta.ppf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e470d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690c7e9",
   "metadata": {},
   "source": [
    "## Coverage simulation over p-grid (n=10 and n=30) (6 points)\n",
    "\n",
    "For each method, estimate coverage:\n",
    "\n",
    "grid: $p \\in \\{0.01, 0.02, …, 0.99\\}$\n",
    "\n",
    "for each p: simulate $B$ binomials $k \\sim Bin(n, p)$\n",
    "\n",
    "build CI\n",
    "\n",
    "- heck whether true p lies inside\n",
    "\n",
    "- compute coverage rate\n",
    "\n",
    "- Plot coverage(p) for each method for:\n",
    "\n",
    "n=10\n",
    "\n",
    "n=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ccf785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b3da73",
   "metadata": {},
   "source": [
    "## Quick take (write 5–8 lines)\n",
    "\n",
    "1) Which method under-covers (coverage < 0.95)? Where exactly: near $p\\approx 0$, $p\\approx 1$, or everywhere?\n",
    "2) Which method is conservative (coverage > 0.95)? What do you pay for that?\n",
    "3) Does the picture change a lot from $n=10$ to $n=30$? Describe the main differences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2228b624",
   "metadata": {},
   "source": [
    "## Average width vs p (3 points)\n",
    "\n",
    "For n=10 and n=30, plot average interval width vs p for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "614c749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cf420",
   "metadata": {},
   "source": [
    "## Answer following questions:\n",
    "\n",
    "1) Which method is usually the narrowest? Is it also well-calibrated by coverage?\n",
    "2) For small $p$ (e.g. $p<0.05$), which methods get much wider and why might that be reasonable?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8230912f",
   "metadata": {},
   "source": [
    "## When do they start working? Vary different n (2 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f4df884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc2152c",
   "metadata": {},
   "source": [
    "## When does asymptotics become OK? (write 2–4 lines)\n",
    "\n",
    "1) For each method, roughly at what $n$ does the *minimum* coverage over $p\\in\\{0.01,\\dots,0.99\\}$ stop being embarrassing?\n",
    "2) Is there a clear “threshold n” after which methods behave similarly? Give a number range.\n",
    "3) Explain in plain words why the edge cases ($p$ near 0 or 1) are hardest for small $n$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f119b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ab9152f",
   "metadata": {},
   "source": [
    "# Task 5. Are you an ML Engineer??? (20 points)\n",
    "\n",
    "Story. You inherit a production ML model. It predicts well, but has too many features: slow, fragile, hard to explain.  \n",
    "You are not asked to code. You are asked to **design a feature selection procedure** based on permutation importance + hypothesis testing.\n",
    "\n",
    "Setup: you have a fixed dataset (train/val/test), a fixed trained model, and a fixed evaluation metric (e.g., RMSE).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ae1c1",
   "metadata": {},
   "source": [
    "## 1) What exactly are we measuring? (4 points)\n",
    "\n",
    "In 3–5 sentences define permutation importance for feature $j$ as a random variable $\\Delta_j$ (what is permuted, what score is computed, what sign means \"useful\").\n",
    "\n",
    "What dataset part you will use for feature selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ddb605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d7bb8",
   "metadata": {},
   "source": [
    "## 2) Statistical question per feature (4 points)\n",
    "\n",
    "Write hypotheses for one feature $j$ using $\\Delta_j$:\n",
    "\n",
    "$\n",
    "H_0: \\#\\#\\# \\\\\n",
    "H_1: \\#\\#\\#\n",
    "$\n",
    "\n",
    "Explain why it is one/two-sided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a58b2e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c1b9b3",
   "metadata": {},
   "source": [
    "## 4) Multiple testing (4 points)\n",
    "\n",
    "You test $d$ features. Explain why \"select all with $p\\le 0.05$\" is wrong.\n",
    "\n",
    "What error rate are you controlling and why is it appropriate for feature selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7f8d65c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3564e43",
   "metadata": {},
   "source": [
    "## 5) Practical significance vs statistical significance (4 points)\n",
    "\n",
    "How would you define practical significance here? How it might me incorporated into the framework?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "72ae43ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c86d1fd",
   "metadata": {},
   "source": [
    "## 6) Make it work at scale (2 points)\n",
    "\n",
    "Permutation is expensive. Propose **two** concrete tricks to reduce compute while keeping decisions reliable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d357e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b161f",
   "metadata": {},
   "source": [
    "# Congrats! You've finished this assignment. How was it? Any feedback is very welcome!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7e4d7441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your thoughts here :) e.g. \"useless, I hate it\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
